{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from relax.import_essentials import *\n",
    "from lime.lime_base import LimeBase\n",
    "from functools import partial\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LimeExplanation(object):\n",
    "    def __init__(self, intercept={}, local_exp={}, score={}, local_pred={}):\n",
    "        self.intercept = intercept\n",
    "        self.local_exp = local_exp\n",
    "        self.score = score\n",
    "        self.local_pred = local_pred\n",
    "\n",
    "    def __str__(self):\n",
    "        return str({\n",
    "            'intercept': self.intercept,\n",
    "            'local_exp': self.local_exp,\n",
    "            'score': self.score,\n",
    "            'local_pred': self.local_pred\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LimeTabularExplainer(object):\n",
    "    def __init__(self, training_data):\n",
    "        freq = np.sum(training_data, axis=0)\n",
    "        freq = freq / len(training_data)\n",
    "        self.freq = freq\n",
    "        # kernel_width = None\n",
    "        kernel_width = np.sqrt(training_data.shape[1]) * .75\n",
    "        kernel_width = float(kernel_width)\n",
    "\n",
    "        def kernel(d, kernel_width):\n",
    "            return np.sqrt(np.exp(-(d ** 2) / kernel_width ** 2))\n",
    "\n",
    "        kernel_fn = partial(kernel, kernel_width=kernel_width)\n",
    "        self.base = LimeBase(kernel_fn)\n",
    "\n",
    "    def generate_neighbors(self, x, cat_arrays, cat_idx, num_samples):\n",
    "        cont_perturbed = x[:, :cat_idx] + np.random.normal(0, 0.1, size=(num_samples, cat_idx))\n",
    "        cont_perturbed = np.clip(cont_perturbed, 0., 1.)\n",
    "        _cat_idx = cat_idx\n",
    "        neighbors = [cont_perturbed]\n",
    "        for col in cat_arrays:\n",
    "            cat_end_idx = cat_idx + len(col)\n",
    "            # one_hot_idx = np.random.randint(0, len(col), size=(num_samples,))\n",
    "            one_hot_idx = np.random.choice(range(len(col)), size=(num_samples,), p=self.freq[cat_idx: cat_end_idx])\n",
    "            cat_feat = np.eye(len(col))[one_hot_idx]\n",
    "\n",
    "            cat_idx = cat_end_idx\n",
    "            neighbors.append(cat_feat)\n",
    "        x = x.reshape(1, -1)\n",
    "        neighbors = np.concatenate(neighbors, axis=-1)\n",
    "        return np.concatenate((x, neighbors), axis=0)\n",
    "\n",
    "    def explain_instance(self,\n",
    "                         x,\n",
    "                         predict_fn,\n",
    "                         cat_arrays,\n",
    "                         cat_idx,\n",
    "                         labels=(1,),\n",
    "                         top_labels=None,\n",
    "                         num_features=200,\n",
    "                         num_samples=500):\n",
    "        neighbors = self.generate_neighbors(\n",
    "            x, cat_arrays=cat_arrays, cat_idx=cat_idx, num_samples=num_samples)\n",
    "        yss = predict_fn(neighbors) #+ 1e-6\n",
    "        yss = np.clip(yss, 1e-6, 1. - 1e-6)\n",
    "        # map to regression model\n",
    "        yss = - np.log(1 / yss - 1)\n",
    "        distances = sklearn.metrics.pairwise_distances(\n",
    "            neighbors, neighbors[0].reshape(1, -1), metric=\"euclidean\"\n",
    "        ).ravel()\n",
    "\n",
    "        self.class_names = [str(x) for x in range(yss[0].shape[0])]\n",
    "\n",
    "        if top_labels:\n",
    "            labels = np.argsort(yss[0])[-top_labels:]\n",
    "\n",
    "        intercept, local_exp, score, local_pred = {}, {}, {}, {}\n",
    "        for label in labels:\n",
    "            (intercept[label],\n",
    "             local_exp[label],\n",
    "             score[label],\n",
    "             local_pred[label]) = self.base.explain_instance_with_data(\n",
    "                 neighbors, yss, distances, label, num_features,\n",
    "                 model_regressor=sklearn.linear_model.Ridge(alpha=1, fit_intercept=False,)\n",
    "             )\n",
    "        return LimeExplanation(\n",
    "            intercept=intercept,\n",
    "            local_exp=local_exp,\n",
    "            score=score,\n",
    "            local_pred=local_pred\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LocalApprox(object):\n",
    "    def __init__(self, train_X, cat_arrays, cat_idx):\n",
    "        # self.explainer = LimeTabularExplainer(train_X, class_names=['0', '1'], discretize_continuous=False)\n",
    "        self.explainer = LimeTabularExplainer(train_X)\n",
    "        self.cat_arrays = cat_arrays\n",
    "        self.cat_idx = cat_idx\n",
    "\n",
    "    def extract_weights(self, x_0, pred_fn, shift=0.1):\n",
    "        # exp = self.explainer.explain_instance(x_0, self.predict_fn, top_labels=1, num_features=200, num_samples=1000)\n",
    "        exp = self.explainer.explain_instance(\n",
    "          x_0, pred_fn, self.cat_arrays, self.cat_idx, num_features=200, num_samples=5000)\n",
    "        coefs = exp.local_exp[1]\n",
    "\n",
    "        intercept = exp.intercept[1]\n",
    "        coefs = sorted(coefs, key=lambda x: x[0])\n",
    "\n",
    "        w = np.array([e[1] for e in coefs])\n",
    "        return w, intercept #np.array(b).reshape(1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfnet.datasets import TabularDataModule\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "dm = TabularDataModule({\n",
    "    \"data_name\": \"student\",\n",
    "    \"continous_cols\": [\n",
    "        \"failures\", \"age\"\n",
    "    ],\n",
    "    \"discret_cols\": [\n",
    "        \"G2\", \"G1\", \"higher\", \"goout\", \"Mjob\", \"Fjob\", \"health\", \n",
    "        \"freetime\", \"absences\", \"Walc\", \"famrel\", \"Medu\", \"Fedu\"\n",
    "    ],\n",
    "    \"batch_size\": 128,\n",
    "    \"data_dir\": \"assets/data/student/gp.csv\"\n",
    "})\n",
    "dm.prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = dm.train_dataset[:]\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03176497, 0.96823503]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict_proba(X[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X, _ = dm.test_dataset[:]\n",
    "lime = LocalApprox(X, cat_arrays=dm.cat_arrays, cat_idx=dm.cat_idx)\n",
    "\n",
    "for x in test_X:\n",
    "    x = x.reshape(1, -1)\n",
    "    coef, intercept = lime.extract_weights(x, lr.predict_proba)\n",
    "    y_pred = lr.predict(x)\n",
    "    assert np.abs(1 / (1 + np.exp(- x @ coef)) - lr.predict_proba(x)[0][1]).item() < 0.01\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03159808])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / (1 + np.exp(- x @ coef))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nbdev2",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
